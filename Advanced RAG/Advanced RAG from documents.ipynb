{
 "cells": [
  {
   "cell_type": "raw",
   "id": "42cf455b",
   "metadata": {},
   "source": [
    "AIM: Implement advanced RAG to query over Azure Vector DB i.e. from Azure Cognitive Search, Integrating with Open AI for QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521f0f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OpenAI_API\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605cdf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e50c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the document\n",
    "# Load, chunk and index the contents of the blog.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8af713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quering over document:\n",
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02648147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the document information over vector db\n",
    "# Chroma db\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e71333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Vecto DB\n",
    "import os\n",
    "\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "from langchain_openai import AzureOpenAIEmbeddings, OpenAIEmbeddings\n",
    "\n",
    "# Option 1: use an OpenAI account\n",
    "openai_api_key: str = \"PLACEHOLDER FOR YOUR API KEY\"\n",
    "openai_api_version: str = \"2023-05-15\"\n",
    "model: str = \"text-embedding-ada-002\"\n",
    "\n",
    "vector_store_address: str = \"YOUR_AZURE_SEARCH_ENDPOINT\"\n",
    "vector_store_password: str = \"YOUR_AZURE_SEARCH_ADMIN_KEY\"\n",
    "    \n",
    "# Option 1: Use OpenAIEmbeddings with OpenAI account\n",
    "embeddings: OpenAIEmbeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=openai_api_key, openai_api_version=openai_api_version, model=model\n",
    ")\n",
    "    \n",
    "index_name: str = \"langchain-vector-demo\"\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"../../modules/state_of_the_union.txt\", encoding=\"utf-8\")\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "vector_store.add_documents(documents=docs)\n",
    "\n",
    "# Perform a similarity search\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"What did the president say about Ketanji Brown Jackson\",\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## advanced search fields\n",
    "from azure.search.documents.indexes.models import (\n",
    "    ScoringProfile,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    TextWeights,\n",
    ")\n",
    "\n",
    "#  Replace OpenAIEmbeddings with AzureOpenAIEmbeddings if Azure OpenAI is your provider.\n",
    "embeddings: OpenAIEmbeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=openai_api_key, openai_api_version=openai_api_version, model=model\n",
    ")\n",
    "embedding_function = embeddings.embed_query\n",
    "\n",
    "fields = [\n",
    "    SimpleField(\n",
    "        name=\"id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"content\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"content_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=len(embedding_function(\"Text\")),\n",
    "        vector_search_profile_name=\"myHnswProfile\",\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"metadata\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field to store the title\n",
    "    SearchableField(\n",
    "        name=\"title\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field for filtering on document source\n",
    "    SimpleField(\n",
    "        name=\"source\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        filterable=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "index_name: str = \"langchain-vector-demo-custom\"\n",
    "\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embedding_function,\n",
    "    fields=fields,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c31affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Cognitive Search as retriever\n",
    "import os\n",
    "\n",
    "from langchain_community.retrievers import (\n",
    "    AzureCognitiveSearchRetriever,\n",
    ")\n",
    "\n",
    "os.environ[\"AZURE_COGNITIVE_SEARCH_SERVICE_NAME\"] = \"<YOUR_ACS_SERVICE_NAME>\"\n",
    "os.environ[\"AZURE_COGNITIVE_SEARCH_INDEX_NAME\"] = \"<YOUR_ACS_INDEX_NAME>\"\n",
    "os.environ[\"AZURE_COGNITIVE_SEARCH_API_KEY\"] = \"<YOUR_API_KEY>\"\n",
    "\n",
    "retriever = AzureCognitiveSearchRetriever(content_key=\"content\", top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbff3830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5de043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6}) # use kwargs to filter over vector db\n",
    "# retrieved_docs = retriever.invoke(\"What are the approaches to Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LLM to retrieve information\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    ").to_messages()\n",
    "example_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96371ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_messages[0].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
